{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "646afabe",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b963615f",
   "metadata": {},
   "source": [
    "## Design Statement\n",
    "Design a conversational journaling assistant to enable young adults in a mental health self-reflection context to express and understand their emotions with personalized sentiment feedback and journaling prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a3f6fc",
   "metadata": {},
   "source": [
    "## Techincal Architecture\n",
    "### System Diagram\n",
    "A[User Journal Entry] --> B[LangChain LLMChain]     \n",
    "B --> C[Sentiment Reflection Generator]     \n",
    "B --> D[Follow-up Prompt Generator]     \n",
    "B --> E[Memory Storage (FAISS)]     \n",
    "C --> F[Streamlit UI Output]        \n",
    "D --> F[Streamlit UI Output]        \n",
    "\n",
    "### Components overview\n",
    "| Component       | Tool                                         | Description                                                            |\n",
    "| --------------- | -------------------------------------------- | ---------------------------------------------------------------------- |\n",
    "| LLM             | Ollama                              | LLM model for sentiment + response generation                          |\n",
    "| LangChain       | `LLMChain`, `PromptTemplate`, `SimpleMemory` | Core logic chaining inputs and outputs                                 |\n",
    "| Streamlit       | Frontend                                     | UI with textbox, buttons, and results                                  |\n",
    "|  Memory | Chroma / FAISS                               | Store past entries and provide history-aware feedback  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247c7dd3",
   "metadata": {},
   "source": [
    "# Steps taken\n",
    "1. Created basic Streamlit UI and added sentiment reflection using the llama3 model\n",
    "2. Created follow-up prompt generation for better self-reflection\n",
    "3. Implemented history with FAISS\n",
    "4. Implemented displaying of past reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b564d12f",
   "metadata": {},
   "source": [
    "## Streamlit App Code\n",
    "the code can be found in app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
